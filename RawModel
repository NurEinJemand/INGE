{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf\n\nimport os\n        \nimport keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations\nfrom keras.models import Sequential\nfrom keras.models import model_from_json\nfrom keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.utils import np_utils, to_categorical\nfrom keras.callbacks import ModelCheckpoint\n\nimport librosa\nfrom librosa import display\n\nimport sklearn\nfrom sklearn import preprocessing\nlb = preprocessing.LabelBinarizer()\nfrom sklearn import model_selection","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-04T17:04:38.159102Z","iopub.execute_input":"2021-10-04T17:04:38.159949Z","iopub.status.idle":"2021-10-04T17:04:46.690507Z","shell.execute_reply.started":"2021-10-04T17:04:38.159775Z","shell.execute_reply":"2021-10-04T17:04:46.689422Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# exemplarische Datenanalyse\n> --> Example: Actor_01/03-01-01-01-01-01-01 --> RAVDESS","metadata":{}},{"cell_type":"code","source":"data = '../input/ravdess-emotional-speech-audio'\nx, fs = librosa.load('../input/ravdess-emotional-speech-audio/Actor_01/03-01-01-01-01-01-01.wav')\nlibrosa.display.waveplot(x, sr=fs)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:04:46.692759Z","iopub.execute_input":"2021-10-04T17:04:46.693491Z","iopub.status.idle":"2021-10-04T17:04:47.862404Z","shell.execute_reply.started":"2021-10-04T17:04:46.693440Z","shell.execute_reply":"2021-10-04T17:04:47.861530Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#mfccs in heatmap\n#sr = sampling_rate\nmfccs = librosa.feature.mfcc(x,sr=fs, n_mfccs = 40)\nprint(mfccs.shape)\nprint(mfccs)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:04:47.864779Z","iopub.execute_input":"2021-10-04T17:04:47.865536Z","iopub.status.idle":"2021-10-04T17:04:47.896323Z","shell.execute_reply.started":"2021-10-04T17:04:47.865480Z","shell.execute_reply":"2021-10-04T17:04:47.895179Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#lautsärke in heatmap\nimport matplotlib.pyplot as plt \nX = librosa.stft(x)\nXdb = librosa.amplitude_to_db(abs(X))\nplt.figure(figsize=(14, 5))\nlibrosa.display.specshow(Xdb, sr=fs, x_axis='time', y_axis='hz')\nplt.colorbar()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-10-04T17:04:47.898673Z","iopub.execute_input":"2021-10-04T17:04:47.899440Z","iopub.status.idle":"2021-10-04T17:04:48.376543Z","shell.execute_reply.started":"2021-10-04T17:04:47.899384Z","shell.execute_reply":"2021-10-04T17:04:48.375238Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Datenverabeitung","metadata":{}},{"cell_type":"markdown","source":"RAVDESS","metadata":{}},{"cell_type":"code","source":"#Ravdess Directory wird geladen\ninput_data = \"../input/ravdess-emotional-speech-audio\"\ndir_list = os.listdir(input_data)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:04:48.378368Z","iopub.execute_input":"2021-10-04T17:04:48.378710Z","iopub.status.idle":"2021-10-04T17:04:48.389152Z","shell.execute_reply.started":"2021-10-04T17:04:48.378654Z","shell.execute_reply":"2021-10-04T17:04:48.388105Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Directory wird vorbereitet\ny_daten = []\ntrain_data = []\ndaten = []\n\nfor  i in range(len(dir_list)):\n    for files in os.walk('../input/ravdess-emotional-speech-audio/' + dir_list[i]):\n        daten = daten + [files]\n\nfor j in range(len(daten)):\n    for m in range(len(daten[j])):\n        for k in range(len(daten[j][m])):\n            if 'wav' in daten[j][m][k]:\n                wort = daten[j][m][k]\n                emo = wort[7:8]\n                y_daten = y_daten + [emo]\n                train_data = train_data + ['../input/ravdess-emotional-speech-audio/'+'Actor_'+wort[18:20]+'/'+wort]","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:04:48.390804Z","iopub.execute_input":"2021-10-04T17:04:48.391102Z","iopub.status.idle":"2021-10-04T17:04:49.294139Z","shell.execute_reply.started":"2021-10-04T17:04:48.391074Z","shell.execute_reply":"2021-10-04T17:04:49.292853Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Ravdess-Aufnahmen werden in MFCCs umgewandelt\nmfccs = np.empty([2880, 40])\nfor i in range(len(dir_list)):\n    wav, sr = librosa.load(train_data[i])\n    zt = librosa.feature.mfcc(wav, sr = sr, n_mfcc=40)\n    for j in range(40):\n        var1 = np.mean(zt[j])\n        mfccs[i][j] = var1","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:04:49.295700Z","iopub.execute_input":"2021-10-04T17:04:49.296042Z","iopub.status.idle":"2021-10-04T17:04:55.548003Z","shell.execute_reply.started":"2021-10-04T17:04:49.296007Z","shell.execute_reply":"2021-10-04T17:04:55.546947Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Crema-D","metadata":{}},{"cell_type":"code","source":"#Crema-D wird in MFCCs umgewandelt\ny_crema = []\ncrema_dir = os.listdir('../input/cremad/AudioWAV')\ncrema_mfccs = np.empty([7442,40])\nfor i in range(len(crema_dir)):\n    emo = crema_dir[i]\n    y_crema = y_crema + [emo[9:12]]\n    wav, sr = librosa.load('../input/cremad/AudioWAV/' + crema_dir[i])\n    zts = librosa.feature.mfcc(wav, sr=sr, n_mfcc=40)\n    for j in range(40):\n        var1 = np.mean(zts[j])\n        crema_mfccs[i][j] = var1\n","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:04:55.551216Z","iopub.execute_input":"2021-10-04T17:04:55.551654Z","iopub.status.idle":"2021-10-04T17:21:42.172755Z","shell.execute_reply.started":"2021-10-04T17:04:55.551604Z","shell.execute_reply":"2021-10-04T17:21:42.171100Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#y_crema Klassen werden in 1-8 umgewandelt, zur Vereinheitlichung \ny_crem = []\nfor i in range(len(y_crema)):\n    if y_crema[i] == 'NEU':\n        y_crem = y_crem + ['1']\n    elif y_crema[i] == 'CAM':\n        y_crem = y_crem + ['2']\n    elif y_crema[i] == 'HAP':\n        y_crem = y_crem + ['3']\n    elif y_crema[i] == 'SAD':\n        y_crem = y_crem + ['4']\n    elif y_crema[i] == 'ANG':\n        y_crem = y_crem + ['5']\n    elif y_crema[i] == 'FEA':\n        y_crem = y_crem + ['6']\n    elif y_crema[i] == 'DIS':\n        y_crem = y_crem + ['7']\n    elif y_crema[i] == 'SUR':\n        y_crem = y_crem + ['8']\n","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:21:42.175527Z","iopub.execute_input":"2021-10-04T17:21:42.175998Z","iopub.status.idle":"2021-10-04T17:21:42.312297Z","shell.execute_reply.started":"2021-10-04T17:21:42.175951Z","shell.execute_reply":"2021-10-04T17:21:42.311006Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"TESS","metadata":{}},{"cell_type":"code","source":"#TESS-Directory wird zur Verabeitung vorbereitet\ndirs = []\nfiles = []\ny_tess = []\ntess_mfccs = np.empty([5600, 40])\n\nfrom sklearn.preprocessing import label_binarize\n\nfor dirname, _, filenames in os.walk('../input/toronto-emotional-speech-set-tess'):\n    for filename in filenames:\n        files = files + [filename]\n        dirs = dirs + [os.path.join(dirname, filename)]\n\nfor i in range(len(files)):\n    ex = files[i]\n    y_tess = y_tess + [ex[-7:-4]]","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:21:42.313988Z","iopub.execute_input":"2021-10-04T17:21:42.314402Z","iopub.status.idle":"2021-10-04T17:21:43.509899Z","shell.execute_reply.started":"2021-10-04T17:21:42.314359Z","shell.execute_reply":"2021-10-04T17:21:43.508997Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#y_tess in Zahlen von 1-8, zur Vereinheitlichung\ny_tess2 = []\nfor i in range(len(y_tess)):\n    if y_tess[i] == 'ral':\n        y_tess2 = y_tess2 + ['1']\n    elif y_tess[i] == 'bkl':\n        y_tess2 = y_tess2 + ['2']\n    elif y_tess[i] == 'ppy':\n        y_tess2 = y_tess2 + ['3']\n    elif y_tess[i] == 'sad':\n        y_tess2 = y_tess2 + ['4']\n    elif y_tess[i] == 'gry':\n        y_tess2 = y_tess2 + ['5']\n    elif y_tess[i] == 'ear':\n        y_tess2 = y_tess2 + ['6']\n    elif y_tess[i] == 'ust':\n        y_tess2 = y_tess2 + ['7']\n    elif y_tess[i] == '_ps':\n        y_tess2 = y_tess2 + ['8']","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:21:43.511116Z","iopub.execute_input":"2021-10-04T17:21:43.511532Z","iopub.status.idle":"2021-10-04T17:21:43.590991Z","shell.execute_reply.started":"2021-10-04T17:21:43.511501Z","shell.execute_reply":"2021-10-04T17:21:43.590124Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#TESS-Daten werden in MFCCs umgewandelt\nfor i in range(len(dirs)):\n    wav, sr = librosa.load(dirs[i])\n    zt = librosa.feature.mfcc(wav, sr = sr, n_mfcc=40)\n    for j in range(40):\n        var1 = np.mean(zt[j])\n        tess_mfccs[i][j] = var1","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:21:43.592153Z","iopub.execute_input":"2021-10-04T17:21:43.592556Z","iopub.status.idle":"2021-10-04T17:33:36.557278Z","shell.execute_reply.started":"2021-10-04T17:21:43.592526Z","shell.execute_reply":"2021-10-04T17:33:36.555635Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#MFCC-Datensätze werden zusammengefügt und normalisiert\nzwischen_mfccs = np.concatenate([mfccs, crema_mfccs, tess_mfccs])\nzwischen_mfccs = preprocessing.normalize(zwischen_mfccs)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:33:36.559620Z","iopub.execute_input":"2021-10-04T17:33:36.560076Z","iopub.status.idle":"2021-10-04T17:33:36.579046Z","shell.execute_reply.started":"2021-10-04T17:33:36.560031Z","shell.execute_reply":"2021-10-04T17:33:36.577853Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#y Datensätze werden zusammengefügt\ny_zwischen = y_daten + y_crem + y_tess2","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:33:36.580721Z","iopub.execute_input":"2021-10-04T17:33:36.581302Z","iopub.status.idle":"2021-10-04T17:33:36.586116Z","shell.execute_reply.started":"2021-10-04T17:33:36.581256Z","shell.execute_reply":"2021-10-04T17:33:36.585095Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#Aufteilung der zusammengeführten Datensätze in Train und Test\ntrain_mfccs, test_mfccs, y_train, y_test = sklearn.model_selection.train_test_split(zwischen_mfccs, y_zwischen, test_size=0.2, random_state=0, shuffle=True)\nprint(crema_mfccs.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:33:36.587650Z","iopub.execute_input":"2021-10-04T17:33:36.588241Z","iopub.status.idle":"2021-10-04T17:33:36.611010Z","shell.execute_reply.started":"2021-10-04T17:33:36.588200Z","shell.execute_reply":"2021-10-04T17:33:36.610016Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#benötigte Dimension für CONV1D Model wird hinzugefügt\ntrain_mfccs = train_mfccs.reshape(train_mfccs.shape[0], train_mfccs.shape[1], 1)\ntest_mfccs = test_mfccs.reshape(test_mfccs.shape[0], test_mfccs.shape[1], 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:33:36.612451Z","iopub.execute_input":"2021-10-04T17:33:36.613059Z","iopub.status.idle":"2021-10-04T17:33:36.620963Z","shell.execute_reply.started":"2021-10-04T17:33:36.613015Z","shell.execute_reply":"2021-10-04T17:33:36.619813Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#Klassen werden in 1*8 Matrix umgewandelt --> Verarbeitung für CONV1D\nfrom sklearn.preprocessing import label_binarize\ny_train = label_binarize(y_train, classes=['1','2','3','4','5','6','7','8'])\ny_test = label_binarize(y_test, classes=['1','2','3','4','5','6','7','8'])","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:33:36.622567Z","iopub.execute_input":"2021-10-04T17:33:36.623304Z","iopub.status.idle":"2021-10-04T17:33:36.659473Z","shell.execute_reply.started":"2021-10-04T17:33:36.623258Z","shell.execute_reply":"2021-10-04T17:33:36.658295Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#y_train, y_test werden in np array umgewandelt, letzte Kontrolle ob Dimensionen stimmen\ny_train = np.array(y_train)\ny_test = np.array(y_test)\nprint(train_mfccs.shape)\nprint(test_mfccs.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:33:36.661201Z","iopub.execute_input":"2021-10-04T17:33:36.661880Z","iopub.status.idle":"2021-10-04T17:33:36.670812Z","shell.execute_reply.started":"2021-10-04T17:33:36.661833Z","shell.execute_reply":"2021-10-04T17:33:36.669800Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv1D(256, 8, padding='same', input_shape=(train_mfccs.shape[1], 1)))\nmodel.add(layers.PReLU())\n\nmodel.add(Conv1D(200, 8,padding='same'))\nmodel.add(layers.PReLU())\nmodel.add(MaxPooling1D(pool_size=(4)))\n\nmodel.add(Conv1D(128, 8,padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(layers.PReLU())\n\nmodel.add(Conv1D(64, 8,padding='same'))\nmodel.add(layers.PReLU())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv1D(54, 8,padding='same'))\nmodel.add(layers.PReLU())\nmodel.add(MaxPooling1D(pool_size=(2)))\n\nmodel.add(Conv1D(32, 8,padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(layers.PReLU())\nmodel.add(Dropout(0.1))\nmodel.add(Flatten())\nmodel.add(Dense(50, activation = 'relu'))\nmodel.add(Dense(8, activation='relu'))\n\nmodel.add(layers.Activation(activations.softmax))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:33:36.672540Z","iopub.execute_input":"2021-10-04T17:33:36.673243Z","iopub.status.idle":"2021-10-04T17:33:36.992772Z","shell.execute_reply.started":"2021-10-04T17:33:36.673198Z","shell.execute_reply":"2021-10-04T17:33:36.988948Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Visualisierung des Models\ntf.keras.utils.plot_model(model, to_file='model.png')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T18:46:34.952883Z","iopub.execute_input":"2021-10-04T18:46:34.953282Z","iopub.status.idle":"2021-10-04T18:46:35.489966Z","shell.execute_reply.started":"2021-10-04T18:46:34.953250Z","shell.execute_reply":"2021-10-04T18:46:35.488565Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\ncnnhistory=model.fit(train_mfccs, y_train, batch_size=64, epochs=100, validation_data=(test_mfccs, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T17:33:36.996571Z","iopub.execute_input":"2021-10-04T17:33:36.996905Z","iopub.status.idle":"2021-10-04T18:26:44.747385Z","shell.execute_reply.started":"2021-10-04T17:33:36.996877Z","shell.execute_reply":"2021-10-04T18:26:44.745858Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#model wird gespeichert\nsave_format='h5'\nmodel.save(\"EmoDet.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-10-04T18:28:51.196381Z","iopub.status.idle":"2021-10-04T18:28:51.197005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyse Ergebnisse","metadata":{}},{"cell_type":"code","source":"#graphische Darstellung der Lernkurven\nhistory = cnnhistory\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'b', label='Training accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T18:28:58.493588Z","iopub.execute_input":"2021-10-04T18:28:58.494258Z","iopub.status.idle":"2021-10-04T18:28:58.847130Z","shell.execute_reply.started":"2021-10-04T18:28:58.494203Z","shell.execute_reply":"2021-10-04T18:28:58.845746Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#Laden eines bereits trainierten Models\n#reconstructed_model = keras.models.load_model('./EmoDet_9_mitcrema_044038.h5')\n#reconstructed_model.fit(test_mfccs, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T18:28:51.199470Z","iopub.status.idle":"2021-10-04T18:28:51.200080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Matrix die Vorhersagen des Models enthält\npred_test = model.predict(test_mfccs)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T18:33:49.375841Z","iopub.execute_input":"2021-10-04T18:33:49.376394Z","iopub.status.idle":"2021-10-04T18:33:51.260834Z","shell.execute_reply.started":"2021-10-04T18:33:49.376340Z","shell.execute_reply":"2021-10-04T18:33:51.259536Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#Berechnung des F1-Scores --> f1 score für jede einzelne Klasse in 1*8 Array\ny_pred = np.zeros([3185, 8])\nfrom sklearn.metrics import f1_score\nfor k in range(3185):\n    for i in range(8):\n        if pred_test[k][i] == np.max(pred_test[k]):\n            y_pred[k][i] = 1\nf1_score(y_test, y_pred, average=None)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T18:37:43.336386Z","iopub.execute_input":"2021-10-04T18:37:43.336839Z","iopub.status.idle":"2021-10-04T18:37:43.561828Z","shell.execute_reply.started":"2021-10-04T18:37:43.336804Z","shell.execute_reply":"2021-10-04T18:37:43.560587Z"},"trusted":true},"execution_count":32,"outputs":[]}]}
